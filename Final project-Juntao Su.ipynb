{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "from munch import Munch\n",
    "from torch.backends import cudnn\n",
    "import torch\n",
    "\n",
    "from core.data_loader import get_train_loader\n",
    "from core.data_loader import get_test_loader\n",
    "from core.solver import Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    return v.lower() in ('true')\n",
    "\n",
    "\n",
    "def subdirs(dname):\n",
    "    return [d for d in os.listdir(dname)\n",
    "            if os.path.isdir(os.path.join(dname, d))]\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    print(args)\n",
    "    cudnn.benchmark = True\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    solver = Solver(args)\n",
    "\n",
    "    if args.mode == 'train':\n",
    "        assert len(subdirs(args.train_img_dir)) == args.num_domains\n",
    "        assert len(subdirs(args.val_img_dir)) == args.num_domains\n",
    "        loaders = Munch(src=get_train_loader(root=args.train_img_dir,\n",
    "                                             which='source',\n",
    "                                             img_size=args.img_size,\n",
    "                                             batch_size=args.batch_size,\n",
    "                                             prob=args.randcrop_prob,\n",
    "                                             num_workers=args.num_workers),\n",
    "                        ref=get_train_loader(root=args.train_img_dir,\n",
    "                                             which='reference',\n",
    "                                             img_size=args.img_size,\n",
    "                                             batch_size=args.batch_size,\n",
    "                                             prob=args.randcrop_prob,\n",
    "                                             num_workers=args.num_workers),\n",
    "                        val=get_test_loader(root=args.val_img_dir,\n",
    "                                            img_size=args.img_size,\n",
    "                                            batch_size=args.val_batch_size,\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=args.num_workers))\n",
    "        solver.train(loaders)\n",
    "    elif args.mode == 'sample':\n",
    "        assert len(subdirs(args.src_dir)) == args.num_domains\n",
    "        assert len(subdirs(args.ref_dir)) == args.num_domains\n",
    "        loaders = Munch(src=get_test_loader(root=args.src_dir,\n",
    "                                            img_size=args.img_size,\n",
    "                                            batch_size=args.val_batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=args.num_workers),\n",
    "                        ref=get_test_loader(root=args.ref_dir,\n",
    "                                            img_size=args.img_size,\n",
    "                                            batch_size=args.val_batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=args.num_workers))\n",
    "        solver.sample(loaders)\n",
    "    elif args.mode == 'eval':\n",
    "        solver.evaluate()\n",
    "    elif args.mode == 'align':\n",
    "        from core.wing import align_faces\n",
    "        align_faces(args, args.inp_dir, args.out_dir)\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=8, beta1=0.0, beta2=0.99, checkpoint_dir='expr/checkpoints', ds_iter=100000, eval_dir='expr/eval', eval_every=50000, f_lr=1e-06, hidden_dim=512, img_size=256, inp_dir='C:\\\\Users\\\\sujun\\\\Desktop\\\\Python Codes\\\\STAT 6289\\\\stargan-v2\\\\assets\\\\representative\\\\custom\\\\male', lambda_cyc=1, lambda_ds=1, lambda_reg=1, lambda_sty=1, latent_dim=16, lm_path='expr/checkpoints/celeba_lm_mean.npz', lr=0.0001, mode='align', num_domains=2, num_outs_per_domain=10, num_workers=4, out_dir='C:\\\\Users\\\\sujun\\\\Desktop\\\\Python Codes\\\\STAT 6289\\\\stargan-v2\\\\assets\\\\representative\\\\custom\\\\output', print_every=10, randcrop_prob=0.5, ref_dir='assets/representative/celeba_hq/ref', result_dir='expr/results', resume_iter=0, sample_dir='expr/samples', sample_every=5000, save_every=10000, seed=777, src_dir='assets/representative/celeba_hq/src', style_dim=64, total_iters=100000, train_img_dir='data/celeba_hq/train', val_batch_size=32, val_img_dir='data/celeba_hq/val', w_hpf=1, weight_decay=0.0001, wing_path='expr/checkpoints/wing.ckpt')\n",
      "Number of parameters of generator: 43467395\n",
      "Number of parameters of mapping_network: 2438272\n",
      "Number of parameters of style_encoder: 20916928\n",
      "Number of parameters of discriminator: 20852290\n",
      "Number of parameters of fan: 6333603\n",
      "Initializing generator...\n",
      "Initializing mapping_network...\n",
      "Initializing style_encoder...\n",
      "Initializing discriminator...\n",
      "Saved the aligned image to custom_male.jpg...\n",
      "Saved the aligned image to cy.jpg...\n",
      "Saved the aligned image to htc.jpg...\n",
      "Saved the aligned image to txl.jpg...\n",
      "Saved the aligned image to zy.jpg...\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# model arguments\n",
    "parser.add_argument('--img_size', type=int, default=256,\n",
    "                    help='Image resolution')\n",
    "parser.add_argument('--num_domains', type=int, default=2,\n",
    "                    help='Number of domains')\n",
    "parser.add_argument('--latent_dim', type=int, default=16,\n",
    "                    help='Latent vector dimension')\n",
    "parser.add_argument('--hidden_dim', type=int, default=512,\n",
    "                    help='Hidden dimension of mapping network')\n",
    "parser.add_argument('--style_dim', type=int, default=64,\n",
    "                    help='Style code dimension')\n",
    "\n",
    "# weight for objective functions\n",
    "parser.add_argument('--lambda_reg', type=float, default=1,\n",
    "                    help='Weight for R1 regularization')\n",
    "parser.add_argument('--lambda_cyc', type=float, default=1,\n",
    "                    help='Weight for cyclic consistency loss')\n",
    "parser.add_argument('--lambda_sty', type=float, default=1,\n",
    "                    help='Weight for style reconstruction loss')\n",
    "parser.add_argument('--lambda_ds', type=float, default=1,\n",
    "                    help='Weight for diversity sensitive loss')\n",
    "parser.add_argument('--ds_iter', type=int, default=100000,\n",
    "                    help='Number of iterations to optimize diversity sensitive loss')\n",
    "parser.add_argument('--w_hpf', type=float, default=1,\n",
    "                    help='weight for high-pass filtering')\n",
    "\n",
    "# training arguments\n",
    "parser.add_argument('--randcrop_prob', type=float, default=0.5,\n",
    "                    help='Probabilty of using random-resized cropping')\n",
    "parser.add_argument('--total_iters', type=int, default=100000,\n",
    "                    help='Number of total iterations')\n",
    "parser.add_argument('--resume_iter', type=int, default=0,\n",
    "                    help='Iterations to resume training/testing')\n",
    "parser.add_argument('--batch_size', type=int, default=8,\n",
    "                    help='Batch size for training')\n",
    "parser.add_argument('--val_batch_size', type=int, default=32,\n",
    "                    help='Batch size for validation')\n",
    "parser.add_argument('--lr', type=float, default=1e-4,\n",
    "                    help='Learning rate for D, E and G')\n",
    "parser.add_argument('--f_lr', type=float, default=1e-6,\n",
    "                    help='Learning rate for F')\n",
    "parser.add_argument('--beta1', type=float, default=0.0,\n",
    "                    help='Decay rate for 1st moment of Adam')\n",
    "parser.add_argument('--beta2', type=float, default=0.99,\n",
    "                    help='Decay rate for 2nd moment of Adam')\n",
    "parser.add_argument('--weight_decay', type=float, default=1e-4,\n",
    "                    help='Weight decay for optimizer')\n",
    "parser.add_argument('--num_outs_per_domain', type=int, default=10,\n",
    "                    help='Number of generated images per domain during sampling')\n",
    "\n",
    "# misc\n",
    "parser.add_argument('--mode', type=str, required=True,\n",
    "                    choices=['train', 'sample', 'eval', 'align'],\n",
    "                    help='This argument is used in solver')\n",
    "parser.add_argument('--num_workers', type=int, default=4,\n",
    "                    help='Number of workers used in DataLoader')\n",
    "parser.add_argument('--seed', type=int, default=777,\n",
    "                    help='Seed for random number generator')\n",
    "\n",
    "# directory for training\n",
    "parser.add_argument('--train_img_dir', type=str, default='data/celeba_hq/train',\n",
    "                    help='Directory containing training images')\n",
    "parser.add_argument('--val_img_dir', type=str, default='data/celeba_hq/val',\n",
    "                    help='Directory containing validation images')\n",
    "parser.add_argument('--sample_dir', type=str, default='expr/samples',\n",
    "                    help='Directory for saving generated images')\n",
    "parser.add_argument('--checkpoint_dir', type=str, default='expr/checkpoints',\n",
    "                    help='Directory for saving network checkpoints')\n",
    "\n",
    "# directory for calculating metrics\n",
    "parser.add_argument('--eval_dir', type=str, default='expr/eval',\n",
    "                    help='Directory for saving metrics, i.e., FID and LPIPS')\n",
    "\n",
    "# directory for testing\n",
    "parser.add_argument('--result_dir', type=str, default='expr/results',\n",
    "                    help='Directory for saving generated images and videos')\n",
    "parser.add_argument('--src_dir', type=str, default='assets/representative/celeba_hq/src',\n",
    "                    help='Directory containing input source images')\n",
    "parser.add_argument('--ref_dir', type=str, default='assets/representative/celeba_hq/ref',\n",
    "                    help='Directory containing input reference images')\n",
    "parser.add_argument('--inp_dir', type=str, default='assets/representative/custom/female',\n",
    "                    help='input directory when aligning faces')\n",
    "parser.add_argument('--out_dir', type=str, default='assets/representative/celeba_hq/src/female',\n",
    "                    help='output directory when aligning faces')\n",
    "\n",
    "# face alignment\n",
    "parser.add_argument('--wing_path', type=str, default='expr/checkpoints/wing.ckpt')\n",
    "parser.add_argument('--lm_path', type=str, default='expr/checkpoints/celeba_lm_mean.npz')\n",
    "\n",
    "# step size\n",
    "parser.add_argument('--print_every', type=int, default=10)\n",
    "parser.add_argument('--sample_every', type=int, default=5000)\n",
    "parser.add_argument('--save_every', type=int, default=10000)\n",
    "parser.add_argument('--eval_every', type=int, default=50000)\n",
    "\n",
    "args = parser.parse_args(['--mode','align',\n",
    "                          '--inp_dir',r'C:\\Users\\sujun\\Desktop\\Python Codes\\STAT 6289\\stargan-v2\\assets\\representative\\custom\\male',\n",
    "                          '--out_dir',r'C:\\Users\\sujun\\Desktop\\Python Codes\\STAT 6289\\stargan-v2\\assets\\representative\\custom\\output'])\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=8, beta1=0.0, beta2=0.99, checkpoint_dir='C:\\\\Users\\\\sujun\\\\Desktop\\\\Python Codes\\\\STAT 6289\\\\stargan-v2\\\\expr\\\\checkpoints\\\\celeba_hq', ds_iter=100000, eval_dir='expr/eval', eval_every=50000, f_lr=1e-06, hidden_dim=512, img_size=256, inp_dir='assets/representative/custom/female', lambda_cyc=1, lambda_ds=1, lambda_reg=1, lambda_sty=1, latent_dim=16, lm_path='expr/checkpoints/celeba_lm_mean.npz', lr=0.0001, mode='sample', num_domains=2, num_outs_per_domain=10, num_workers=4, out_dir='assets/representative/celeba_hq/src/female', print_every=10, randcrop_prob=0.5, ref_dir='C:\\\\Users\\\\sujun\\\\Desktop\\\\Python Codes\\\\STAT 6289\\\\stargan-v2\\\\assets\\\\representative\\\\celeba_hq\\\\ref', result_dir='C:\\\\Users\\\\sujun\\\\Desktop\\\\Python Codes\\\\STAT 6289\\\\stargan-v2\\\\expr\\\\results\\\\custom', resume_iter=100000, sample_dir='expr/samples', sample_every=5000, save_every=10000, seed=777, src_dir='C:\\\\Users\\\\sujun\\\\Desktop\\\\Python Codes\\\\STAT 6289\\\\stargan-v2\\\\assets\\\\representative\\\\custom\\\\output', style_dim=64, total_iters=100000, train_img_dir='data/celeba_hq/train', val_batch_size=32, val_img_dir='data/celeba_hq/val', w_hpf=1.0, weight_decay=0.0001, wing_path='expr/checkpoints/wing.ckpt')\n",
      "Number of parameters of generator: 43467395\n",
      "Number of parameters of mapping_network: 2438272\n",
      "Number of parameters of style_encoder: 20916928\n",
      "Number of parameters of discriminator: 20852290\n",
      "Number of parameters of fan: 6333603\n",
      "Initializing generator...\n",
      "Initializing mapping_network...\n",
      "Initializing style_encoder...\n",
      "Initializing discriminator...\n",
      "Preparing DataLoader for the generation phase...\n",
      "Preparing DataLoader for the generation phase...\n",
      "Loading checkpoint from C:\\Users\\sujun\\Desktop\\Python Codes\\STAT 6289\\stargan-v2\\expr\\checkpoints\\celeba_hq\\100000_nets_ema.ckpt...\n",
      "Working on C:\\Users\\sujun\\Desktop\\Python Codes\\STAT 6289\\stargan-v2\\expr\\results\\custom\\reference.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_ref:   0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on C:\\Users\\sujun\\Desktop\\Python Codes\\STAT 6289\\stargan-v2\\expr\\results\\custom\\video_ref.mp4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_ref: 100%|██████████| 32/32 [00:56<00:00,  1.75s/it]\n",
      "writing video to C:\\Users\\sujun\\Desktop\\Python Codes\\STAT 6289\\stargan-v2\\expr\\results\\custom\\video_ref.mp4: 100%|██████████| 940/940 [00:15<00:00, 61.65it/s]\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# model arguments\n",
    "parser.add_argument('--img_size', type=int, default=256,\n",
    "                    help='Image resolution')\n",
    "parser.add_argument('--num_domains', type=int, default=2,\n",
    "                    help='Number of domains')\n",
    "parser.add_argument('--latent_dim', type=int, default=16,\n",
    "                    help='Latent vector dimension')\n",
    "parser.add_argument('--hidden_dim', type=int, default=512,\n",
    "                    help='Hidden dimension of mapping network')\n",
    "parser.add_argument('--style_dim', type=int, default=64,\n",
    "                    help='Style code dimension')\n",
    "\n",
    "# weight for objective functions\n",
    "parser.add_argument('--lambda_reg', type=float, default=1,\n",
    "                    help='Weight for R1 regularization')\n",
    "parser.add_argument('--lambda_cyc', type=float, default=1,\n",
    "                    help='Weight for cyclic consistency loss')\n",
    "parser.add_argument('--lambda_sty', type=float, default=1,\n",
    "                    help='Weight for style reconstruction loss')\n",
    "parser.add_argument('--lambda_ds', type=float, default=1,\n",
    "                    help='Weight for diversity sensitive loss')\n",
    "parser.add_argument('--ds_iter', type=int, default=100000,\n",
    "                    help='Number of iterations to optimize diversity sensitive loss')\n",
    "parser.add_argument('--w_hpf', type=float, default=1,\n",
    "                    help='weight for high-pass filtering')\n",
    "\n",
    "# training arguments\n",
    "parser.add_argument('--randcrop_prob', type=float, default=0.5,\n",
    "                    help='Probabilty of using random-resized cropping')\n",
    "parser.add_argument('--total_iters', type=int, default=100000,\n",
    "                    help='Number of total iterations')\n",
    "parser.add_argument('--resume_iter', type=int, default=0,\n",
    "                    help='Iterations to resume training/testing')\n",
    "parser.add_argument('--batch_size', type=int, default=8,\n",
    "                    help='Batch size for training')\n",
    "parser.add_argument('--val_batch_size', type=int, default=32,\n",
    "                    help='Batch size for validation')\n",
    "parser.add_argument('--lr', type=float, default=1e-4,\n",
    "                    help='Learning rate for D, E and G')\n",
    "parser.add_argument('--f_lr', type=float, default=1e-6,\n",
    "                    help='Learning rate for F')\n",
    "parser.add_argument('--beta1', type=float, default=0.0,\n",
    "                    help='Decay rate for 1st moment of Adam')\n",
    "parser.add_argument('--beta2', type=float, default=0.99,\n",
    "                    help='Decay rate for 2nd moment of Adam')\n",
    "parser.add_argument('--weight_decay', type=float, default=1e-4,\n",
    "                    help='Weight decay for optimizer')\n",
    "parser.add_argument('--num_outs_per_domain', type=int, default=10,\n",
    "                    help='Number of generated images per domain during sampling')\n",
    "\n",
    "# misc\n",
    "parser.add_argument('--mode', type=str, required=True,\n",
    "                    choices=['train', 'sample', 'eval', 'align'],\n",
    "                    help='This argument is used in solver')\n",
    "parser.add_argument('--num_workers', type=int, default=4,\n",
    "                    help='Number of workers used in DataLoader')\n",
    "parser.add_argument('--seed', type=int, default=777,\n",
    "                    help='Seed for random number generator')\n",
    "\n",
    "# directory for training\n",
    "parser.add_argument('--train_img_dir', type=str, default='data/celeba_hq/train',\n",
    "                    help='Directory containing training images')\n",
    "parser.add_argument('--val_img_dir', type=str, default='data/celeba_hq/val',\n",
    "                    help='Directory containing validation images')\n",
    "parser.add_argument('--sample_dir', type=str, default='expr/samples',\n",
    "                    help='Directory for saving generated images')\n",
    "parser.add_argument('--checkpoint_dir', type=str, default='expr/checkpoints',\n",
    "                    help='Directory for saving network checkpoints')\n",
    "\n",
    "# directory for calculating metrics\n",
    "parser.add_argument('--eval_dir', type=str, default='expr/eval',\n",
    "                    help='Directory for saving metrics, i.e., FID and LPIPS')\n",
    "\n",
    "# directory for testing\n",
    "parser.add_argument('--result_dir', type=str, default='expr/results',\n",
    "                    help='Directory for saving generated images and videos')\n",
    "parser.add_argument('--src_dir', type=str, default='assets/representative/celeba_hq/src',\n",
    "                    help='Directory containing input source images')\n",
    "parser.add_argument('--ref_dir', type=str, default='assets/representative/celeba_hq/ref',\n",
    "                    help='Directory containing input reference images')\n",
    "parser.add_argument('--inp_dir', type=str, default='assets/representative/custom/female',\n",
    "                    help='input directory when aligning faces')\n",
    "parser.add_argument('--out_dir', type=str, default='assets/representative/celeba_hq/src/female',\n",
    "                    help='output directory when aligning faces')\n",
    "\n",
    "# face alignment\n",
    "parser.add_argument('--wing_path', type=str, default='expr/checkpoints/wing.ckpt')\n",
    "parser.add_argument('--lm_path', type=str, default='expr/checkpoints/celeba_lm_mean.npz')\n",
    "\n",
    "# step size\n",
    "parser.add_argument('--print_every', type=int, default=10)\n",
    "parser.add_argument('--sample_every', type=int, default=5000)\n",
    "parser.add_argument('--save_every', type=int, default=10000)\n",
    "parser.add_argument('--eval_every', type=int, default=50000)\n",
    "\n",
    "args = parser.parse_args(['--mode','sample', '--num_domains','2','--resume_iter','100000','--w_hpf','1',\n",
    "                          '--checkpoint_dir',r'C:\\Users\\sujun\\Desktop\\Python Codes\\STAT 6289\\stargan-v2\\expr\\checkpoints\\celeba_hq',\n",
    "                          '--result_dir',r'C:\\Users\\sujun\\Desktop\\Python Codes\\STAT 6289\\stargan-v2\\expr\\results\\custom',\n",
    "                          '--src_dir',r'C:\\Users\\sujun\\Desktop\\Python Codes\\STAT 6289\\stargan-v2\\assets\\representative\\custom\\output',\n",
    "                          '--ref_dir',r'C:\\Users\\sujun\\Desktop\\Python Codes\\STAT 6289\\stargan-v2\\assets\\representative\\celeba_hq\\ref'])\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animal faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=8, beta1=0.0, beta2=0.99, checkpoint_dir='C:\\\\Users\\\\sujun\\\\Desktop\\\\Python Codes\\\\STAT 6289\\\\stargan-v2\\\\expr\\\\checkpoints\\\\afhq', ds_iter=100000, eval_dir='expr/eval', eval_every=50000, f_lr=1e-06, hidden_dim=512, img_size=256, inp_dir='assets/representative/custom/female', lambda_cyc=1, lambda_ds=1, lambda_reg=1, lambda_sty=1, latent_dim=16, lm_path='expr/checkpoints/celeba_lm_mean.npz', lr=0.0001, mode='sample', num_domains=3, num_outs_per_domain=10, num_workers=4, out_dir='assets/representative/celeba_hq/src/female', print_every=10, randcrop_prob=0.5, ref_dir='C:\\\\Users\\\\sujun\\\\Desktop\\\\Python Codes\\\\STAT 6289\\\\stargan-v2\\\\assets\\\\representative\\\\afhq\\\\ref', result_dir='C:\\\\Users\\\\sujun\\\\Desktop\\\\Python Codes\\\\STAT 6289\\\\stargan-v2\\\\expr\\\\results\\\\custom', resume_iter=100000, sample_dir='expr/samples', sample_every=5000, save_every=10000, seed=777, src_dir='C:\\\\Users\\\\sujun\\\\Desktop\\\\Python Codes\\\\STAT 6289\\\\stargan-v2\\\\assets\\\\representative\\\\custom\\\\output', style_dim=64, total_iters=100000, train_img_dir='data/celeba_hq/train', val_batch_size=32, val_img_dir='data/celeba_hq/val', w_hpf=0.0, weight_decay=0.0001, wing_path='expr/checkpoints/wing.ckpt')\n",
      "Number of parameters of generator: 33892995\n",
      "Number of parameters of mapping_network: 3259072\n",
      "Number of parameters of style_encoder: 20949760\n",
      "Number of parameters of discriminator: 20852803\n",
      "Initializing generator...\n",
      "Initializing mapping_network...\n",
      "Initializing style_encoder...\n",
      "Initializing discriminator...\n",
      "Preparing DataLoader for the generation phase...\n",
      "Preparing DataLoader for the generation phase...\n",
      "Loading checkpoint from C:\\Users\\sujun\\Desktop\\Python Codes\\STAT 6289\\stargan-v2\\expr\\checkpoints\\afhq\\100000_nets_ema.ckpt...\n",
      "Working on C:\\Users\\sujun\\Desktop\\Python Codes\\STAT 6289\\stargan-v2\\expr\\results\\custom\\reference.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_ref:   0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on C:\\Users\\sujun\\Desktop\\Python Codes\\STAT 6289\\stargan-v2\\expr\\results\\custom\\video_ref.mp4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "video_ref: 100%|██████████| 28/28 [00:33<00:00,  1.21s/it]\n",
      "writing video to C:\\Users\\sujun\\Desktop\\Python Codes\\STAT 6289\\stargan-v2\\expr\\results\\custom\\video_ref.mp4: 100%|██████████| 785/785 [00:08<00:00, 92.51it/s] \n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# model arguments\n",
    "parser.add_argument('--img_size', type=int, default=256,\n",
    "                    help='Image resolution')\n",
    "parser.add_argument('--num_domains', type=int, default=2,\n",
    "                    help='Number of domains')\n",
    "parser.add_argument('--latent_dim', type=int, default=16,\n",
    "                    help='Latent vector dimension')\n",
    "parser.add_argument('--hidden_dim', type=int, default=512,\n",
    "                    help='Hidden dimension of mapping network')\n",
    "parser.add_argument('--style_dim', type=int, default=64,\n",
    "                    help='Style code dimension')\n",
    "\n",
    "# weight for objective functions\n",
    "parser.add_argument('--lambda_reg', type=float, default=1,\n",
    "                    help='Weight for R1 regularization')\n",
    "parser.add_argument('--lambda_cyc', type=float, default=1,\n",
    "                    help='Weight for cyclic consistency loss')\n",
    "parser.add_argument('--lambda_sty', type=float, default=1,\n",
    "                    help='Weight for style reconstruction loss')\n",
    "parser.add_argument('--lambda_ds', type=float, default=1,\n",
    "                    help='Weight for diversity sensitive loss')\n",
    "parser.add_argument('--ds_iter', type=int, default=100000,\n",
    "                    help='Number of iterations to optimize diversity sensitive loss')\n",
    "parser.add_argument('--w_hpf', type=float, default=1,\n",
    "                    help='weight for high-pass filtering')\n",
    "\n",
    "# training arguments\n",
    "parser.add_argument('--randcrop_prob', type=float, default=0.5,\n",
    "                    help='Probabilty of using random-resized cropping')\n",
    "parser.add_argument('--total_iters', type=int, default=100000,\n",
    "                    help='Number of total iterations')\n",
    "parser.add_argument('--resume_iter', type=int, default=0,\n",
    "                    help='Iterations to resume training/testing')\n",
    "parser.add_argument('--batch_size', type=int, default=8,\n",
    "                    help='Batch size for training')\n",
    "parser.add_argument('--val_batch_size', type=int, default=32,\n",
    "                    help='Batch size for validation')\n",
    "parser.add_argument('--lr', type=float, default=1e-4,\n",
    "                    help='Learning rate for D, E and G')\n",
    "parser.add_argument('--f_lr', type=float, default=1e-6,\n",
    "                    help='Learning rate for F')\n",
    "parser.add_argument('--beta1', type=float, default=0.0,\n",
    "                    help='Decay rate for 1st moment of Adam')\n",
    "parser.add_argument('--beta2', type=float, default=0.99,\n",
    "                    help='Decay rate for 2nd moment of Adam')\n",
    "parser.add_argument('--weight_decay', type=float, default=1e-4,\n",
    "                    help='Weight decay for optimizer')\n",
    "parser.add_argument('--num_outs_per_domain', type=int, default=10,\n",
    "                    help='Number of generated images per domain during sampling')\n",
    "\n",
    "# misc\n",
    "parser.add_argument('--mode', type=str, required=True,\n",
    "                    choices=['train', 'sample', 'eval', 'align'],\n",
    "                    help='This argument is used in solver')\n",
    "parser.add_argument('--num_workers', type=int, default=4,\n",
    "                    help='Number of workers used in DataLoader')\n",
    "parser.add_argument('--seed', type=int, default=777,\n",
    "                    help='Seed for random number generator')\n",
    "\n",
    "# directory for training\n",
    "parser.add_argument('--train_img_dir', type=str, default='data/celeba_hq/train',\n",
    "                    help='Directory containing training images')\n",
    "parser.add_argument('--val_img_dir', type=str, default='data/celeba_hq/val',\n",
    "                    help='Directory containing validation images')\n",
    "parser.add_argument('--sample_dir', type=str, default='expr/samples',\n",
    "                    help='Directory for saving generated images')\n",
    "parser.add_argument('--checkpoint_dir', type=str, default='expr/checkpoints',\n",
    "                    help='Directory for saving network checkpoints')\n",
    "\n",
    "# directory for calculating metrics\n",
    "parser.add_argument('--eval_dir', type=str, default='expr/eval',\n",
    "                    help='Directory for saving metrics, i.e., FID and LPIPS')\n",
    "\n",
    "# directory for testing\n",
    "parser.add_argument('--result_dir', type=str, default='expr/results',\n",
    "                    help='Directory for saving generated images and videos')\n",
    "parser.add_argument('--src_dir', type=str, default='assets/representative/celeba_hq/src',\n",
    "                    help='Directory containing input source images')\n",
    "parser.add_argument('--ref_dir', type=str, default='assets/representative/celeba_hq/ref',\n",
    "                    help='Directory containing input reference images')\n",
    "parser.add_argument('--inp_dir', type=str, default='assets/representative/custom/female',\n",
    "                    help='input directory when aligning faces')\n",
    "parser.add_argument('--out_dir', type=str, default='assets/representative/celeba_hq/src/female',\n",
    "                    help='output directory when aligning faces')\n",
    "\n",
    "# face alignment\n",
    "parser.add_argument('--wing_path', type=str, default='expr/checkpoints/wing.ckpt')\n",
    "parser.add_argument('--lm_path', type=str, default='expr/checkpoints/celeba_lm_mean.npz')\n",
    "\n",
    "# step size\n",
    "parser.add_argument('--print_every', type=int, default=10)\n",
    "parser.add_argument('--sample_every', type=int, default=5000)\n",
    "parser.add_argument('--save_every', type=int, default=10000)\n",
    "parser.add_argument('--eval_every', type=int, default=50000)\n",
    "\n",
    "args = parser.parse_args(['--mode','sample', '--num_domains','3','--resume_iter','100000','--w_hpf','0',\n",
    "                          '--checkpoint_dir',r'C:\\Users\\sujun\\Desktop\\Python Codes\\STAT 6289\\stargan-v2\\expr\\checkpoints\\afhq',\n",
    "                          '--result_dir',r'C:\\Users\\sujun\\Desktop\\Python Codes\\STAT 6289\\stargan-v2\\expr\\results\\custom',\n",
    "                          '--src_dir',r'C:\\Users\\sujun\\Desktop\\Python Codes\\STAT 6289\\stargan-v2\\assets\\representative\\custom\\output',\n",
    "                          '--ref_dir',r'C:\\Users\\sujun\\Desktop\\Python Codes\\STAT 6289\\stargan-v2\\assets\\representative\\afhq\\ref'])\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
